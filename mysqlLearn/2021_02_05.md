# MySQL 事务以及索引相关

## 什么是事务

- 在MySQL中的事务是由存储引擎实现的，而且支持事务的存储引擎不多，主要了解InnoDB存储引擎中的事务。

- 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。

- 事务用来管理 DDL、DML、DCL 操作，比如 insert,update,delete 语句，默认是自动提交的。

## 事务的四大特性

1. Atomicity（原子性）：构成事务的的所有操作必须是一个逻辑单元，要么全部成功，要么全部失败。
2. Consistency（一致性）：数据库在事务执行前后状态都必须是稳定的或者是一致的，就是说事务开始和结束后，数据库的完整性不会被破坏。
3. Isolation（隔离性）：事务之间不会相互影响。由锁机制和MVCC机制来实现的，其中MVCC(多版本并发控制)：优化读写性能（读不加锁、读写不冲突），四种隔离级别为RU（读未提交）、RC（读已提交）、RR（可重复读）、SERIALIZABLE （串行化）。
4. Durability（持久性）：事务执行成功后必须全部写入磁盘，事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失。

### ACID 实现原理

事务的隔离性由多版本控制机制和锁实现，而原子性、一致性和持久性通过InnoDB的redo log、undo log和ForceLog at Commit机制来实现。

#### 重做日志 Redo Log

> 如果要存储数据则先存储数据的日志，一旦内存崩了，则可以从日志找重做日志保证了数据的可靠性，InnoDB采用了Write Ahead Log（预写日志）策略，即当事务提交时，先写重做日志，然后再择时将脏页写入磁盘。如果发生宕机导致数据丢失，就通过重做日志进行数据恢复。

#### 回滚日志 Undo log

> 数据库崩溃重启后需要从redo log中把未落盘的脏页数据恢复出来，重新写入磁盘，保证用户的数据不丢失。当然，在崩溃恢复中还需要回滚没有提交的事务。由于回滚操作需要undo日志的支持，undo日志的完整性和可靠性需要redo日志来保证，所以崩溃恢复先做redo恢复数据，然后做undo回滚。

> 所以，在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。

#### Force Log at Commit 机制

> 它实现事务的持久性，即当事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，然后事务的提交操作完成才算完成。为了确保每次日志都写入到重做日志文件，在每次将重做日志缓冲写入重做日志后，必须调用一次fsync操作（操作系统），将缓冲文件从文件系统缓存中真正写入磁盘。

总结一下就是redo log用于在崩溃时恢复数据，undo log用于对事务的影响进行撤销，也可以用于多版本控制。而Force Log at Commit机制保证事务提交后redo log日志都已经持久化。

### 原子性

> 原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做。例如银行转账要么成功，要么失败，是不存在中间的状态！

Undo Log是实现原子性的关键，靠的就是undo log。当事务对数据库进行修改时，InnoDB会生成对应的undo log。undo log它属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。

以update操作为例：当事务执行 update 时，其生成的 undo log 中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到 update 之前的状态。

### 持久性

> 持久性是指事务执行成功后必须全部写入磁盘，事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失。

InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中。

虽然Buffer Pool的使用大大提高了读写数据的效率，但是也有别的问题，当MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

于是，优秀的程序员们引入了redo log，当我们对数据进行修改时，除了修改Buffer Pool中的数据，还会在redo log中记录这次操作。当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。

还有一点必须知道就是redo log采用的是WAL策略，所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。

### 隔离性

在MySQL隔离性中，一般有两种情况：

1. 要求同一时刻只能有一个事务对数据进行写操作，InnoDB通过锁机制来保证这一点。
2. 在进行读操作的时候，可能出现脏读、不可重复读、幻读的问题。

首先讲第一种情况，MySQL要求同一时刻只能有一个事务对数据进行写操作，InnoDB通过锁机制来保证这一点。

锁机制的基本原理可以理解为：事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。

至于锁机制中的锁，一般就是之前讲到的MySQL锁，大家可以去看看这篇MySQL锁的内容。

接着讲第二种情况，读操作可能出现脏读、不可重复读、幻读的问题。

隔离性追求的是并发情形下事务之间互不干扰，但是在事务的并发操作中可能会出现一些问题：

1. 丢失更新：两个事务针对同一数据都发生修改操作时，会存在丢失更新问题。
2. 脏读：对于两个事务 T1，T2，T1 读取了已经被 T2 更新但还没有被提交的字段。之后，若 T2 回滚，T1读取的内容就是临时且无效的。
3. 不可重复读：对于两个事务T1，T2，T1 读取了一个字段，然后 T2 更新了该字段。之后，T1再次读取同一个字段，发现字段的内容不一样。要求，多次读取数据的时候，在一个事务中读出的都应该是一样的。一般是由于 update 操作引发，所以将来执行的时候要特别注意。
4. 幻读：对于两个事务T1，T2，T1 从一个表中读取了一个字段，然后 T2 在该表中插入了一些新的行。之后。如果 T1 再次读取同一个表，就会多出几行。就是发现数据的数量不一样。要求，在一个事务中多次去读取数据的时候都应该是一样的。

- 读取数据前新增行，发现数据数量不一致为幻读。
- 读取数据发现字段数据不一致为不可重复
- 读取未提交字段后回滚，该数据无效，为脏读

虽然有上述这些问题，但MySQL数据库为我们提供的四种隔离级别（由低到高）：

1. Read uncommitted (读未提交)：最低级别，任何情况都无法保证。
2. Read committed (RC，读已提交)：可避免脏读的发生。
3. Repeatable read (RR，可重复读)：可避免脏读、不可重复读的发生。(InnoDB默认级别为RR，它可以解决幻读，主要原因是Next-Key（Gap）锁，只有RR才能使用Next-Key锁)
4. Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。

解决脏读、不可重复读、幻读的问题使用的是MVCC，即多版本的并发控制协议。它说的就是在同一时刻，不同的事务读取到的数据可能是不同的(即多版本)。

MVCC最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要是依靠数据的隐藏列( 也可以称之为标记位 )和undo log。其中数据的隐藏列包括了该行数据的版本号、删除时间、指向undo log的指针等等；当读取数据时，MySQL可以通过隐藏列判断是否需要回滚并找到回滚需要的undo log，从而实现MVCC。

### MVCC如何解决脏读、不可重复读、幻读的问题

1. **MVCC 解决脏读问题**

> 当事务T1在第三个时刻读取自己的余额时，会发现数据已被T2事务修改，并且T2的状态还没有提交。此时事务A读取最新数据后，根据数据的undo log执行回滚操作，得到事务T2修改前的数据，从而避免了脏读。

2. **MVCC 解决不可重复读**
   
> 当事务T1在第二个时刻第一次读取数据时，会记录该数据的版本号（数据的版本号是以row为单位记录的），假设版本号为1；当事务T2对自己的余额进行修改并且提交时，该行记录的版本号增加，假设版本号为2；当事务T1在第五个时刻再一次读取数据时，发现数据的版本号2大于第一次读取时记录的版本号1，因此会根据undo log执行回滚操作，得到版本号为1时的数据，从而实现了可重复读。

3. **MVCC 解决幻读**

> next-key lock是行锁的一种，实现相当于record lock(记录锁) + gap lock(间隙锁)，它的特点是不仅会锁住记录本身(record lock的功能)，还会锁定一个范围(gap lock的功能)。

> 当事务T1在第二个时刻第一次读取id(0, 5)数据时，会进行标记，标记内容包括数据的版本号等，并且标记的不只是id=1的数据，还将范围(0,5)进行了标记。我们接着在第三个时刻插入新的用户并且提交事务，最后第五个时刻再次读取id(0, 5)数据时，便可以发现id=2的数据比之前标记的版本号更高，此时再结合undo log执行回滚操作，避免了幻读。

> 稍微总结下，InnoDB通过锁机制、数据的隐藏列、undo log和类next-key lock，实现了一定程度的隔离性，可以满足大多数场景的需要。不过需要说明的是，RR虽然避免了幻读问题，但是毕竟不是Serializable，不能保证完全的隔离。

### 一致性

> 一致性是事物追求的最终目标，前面提到的原子性，隔离性，持久性都是为了保证数据库的一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。

### MySQL 查询优化

```
CREATE TABLE `t_user` (
  `id` int NOT NULL,
  `user_name` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `address` varchar(255) DEFAULT NULL,
  `create_time` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;


DELIMITER //
CREATE PROCEDURE user_insert()
BEGIN
DECLARE i INT DEFAULT 0;
WHILE i<1000000
DO
INSERT INTO t_user(id, user_name, address,  create_time) VALUES (i, CONCAT('mayun',i), '浙江杭州', now());
SET i=i+1;
END WHILE ;
commit;
END //
CALL user_insert();//
```

创建 t_user 表并插入一百万条数据

limit 500000时
**使用查询语句，查看分页 limit 到一定值的耗时是多少**
```
select * from t_user limit 500000, 10;
// 耗时 0.12 秒
```

**使用子查询优化后的查询**
```
select * from t_user where id>=(select id from t_user order by id limit 500000,1) limit 10;
// 耗时 0.09 秒
```

**使用 JOIN 分页时**
```
select * from t_user t1 inner join (select id from t_user order by id limit 900000,10) t2 on t1.id=t2.id;
// 耗时 0.08s
```

**使用前一次查询的最大 ID**
```
select * from t_user where id > 999990 order by id limit 10;
```

### 索引优化

#### 使用普通索引进行优化
当前没有索引优化查询

```
select * from t_user where user_name like 'mayun100%';
// 耗时三秒
```

给当前 user_name 增加普通索引
```
alter table t_user add INDEX idx_user_name(user_name) using BTREE;
```

再次查询耗时 0.01s，使用普通索引后查询效率明显增加

#### 使用复合索引进行优化

复合索引什么时候用，为什么用。
- 单表中查询，条件语句中具有较多个字段
- 使用索引会影响写的效率，需要研究建立最优秀的索引

user_name,address,create_time建立复合索引

MySQL 建立复合索引时实际建立了(user_name)、(user_name,address)、(user_name,address,create_time)三个索引，每增加一个索引，都会增加写操作的开销和磁盘空间开销，目前这里使用复合索引一个顶三个。

当我们select user_name,address,create_time from t_user where user_name=xx and address = xxx时，MySQL可以直接通过遍历索引取得数据，无需回表，这减少了很多的随机IO操作。所以，在真正的实际应用中，这就是覆盖索引，是复合索引中主要的提升性能的优化手段之一。

### SQL查询优化

1. 避免使用 or

```
select * from t_user t where t.user_name like 'mayun100%' or t.address='浙江杭州';
```
这条语句没有使用到索引，因为当 or 左右查询字段只有一个是索引，该索引失效；只有当 or 左右查询字段均为索引时，才会生效;

2. 不要使用like '%xx' %在左边时索引失效
```
select * from t_user t where t.user_name like 'mayun100%' or t.address='浙江杭州';
```
3. 使用复合索引时没有遵循最左匹配原则：

最左匹配原则：查询语句的查询条件里面，必须要有复合索引中最左边的字段，复合索引才会生效
```
select * from t_user t where t.address='浙江杭州' and t.create_time='2021-02-07 11:09:58';
// 耗时 0.27s 
```
以下语句使用了最左匹配的：
```
select * from t_user t where t.user_name="mayun1" and t.address='浙江杭州' and t.create_time='2021-02-07 11:09:58';
// 耗时 0.01s
```
4. 不要让数据类型出现隐式转化
```
select * from t_user t where t.user_name=110;
// 耗时 0.42s
```
不出现隐式转化
```
select * from t_user t where t.user_name='110';
// 耗时 0.00s
```
5. 不要在索引字段上使用 not, <>, !=, 一样会导致索引失效
6. 分解关联查询
```
select * from t_user u LEFT JOIN t_order o on u.id=o.user_id where u.user_name='mayun110';

// 可以分解成

select * from t_user u where u.user_name='mayun110';

select * from y_order o where o.user_id in (u.id1,u.id2...);
```
7. 小表驱动大表

小的数据集驱动大的数据集。如：以 t_user，t_order 两表为例，两表通过t_user的id字段进行关联。

当 t_order 表的数据集小于t_user表时，用 in 优化 exist，使用 in，两表执行顺序是先查 t_order 表，再查 t_user 表

```
select * from t_user where id in (select user_id from t_order);
```

当 t_user 表的数据集小于 t_order 表时，用 exist 优化 in，使用 exists，两表执行顺序是先查 t_user 表，再查 t_order 表
```
select * from t_user where exists (select 1 from 8 where t_order.user_id=t_user.id)
```
### 数据库性能优化

##### 开启查询缓存
- 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。 MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。
- 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。
- 既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：
> 任何的查询语句在开始之前都必须经过检查，即使这条 SQL 语句永远不会命中缓存
> 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗
- 基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：
  批量插入代替循环单条插入 　 . 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 　 . 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存 　　最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。 　　当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等。

#### 语法解析和预处理

- MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。

### 表字段优化

很多系统一开始并没有考虑表字段拆分的问题，因为拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下，而事实上很多时候 MySQL 单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量：

**如何去优化字段**
1. 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED
2. 单表不要有太多字段，建议在15以内
3. 尽量使用TIMESTAMP而非DATETIME
4. 使用枚举或整数代替字符串类型
5. VARCHAR的长度只分配真正需要的空间
6. 避免使用NULL字段，很难查询优化且占用额外索引空间
7. 用整型来存IP

### 分布式场景下常用优化手段

1. 升级硬件
根据MySQL是CPU密集型还是I/O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能
2. 读写分离
也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离
3. 使用缓存
缓存可以发生在这些层次：

MySQL内部：在系统内核参数优化介绍了相关设置

数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object

应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object

Web层：针对web页面做缓存

浏览器客户端：用户端的缓存

可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式：

直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。

回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。

4. 水瓶拆分

## MySQL 之 Buffer Pool

### Buffer Pool 会不会产生内存碎片

MySQL InnoDB 缓冲池。里面缓存着大量数据（数据页），使 CPU 读取或写入数据时，不直接和低速的磁盘打交道，直接和缓冲区进行交互，从而解决了因为磁盘性能慢导致的数据库性能差的问题。

